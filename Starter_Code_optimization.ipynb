{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "id": "d85347ff",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>EIN</th>\n",
                            "      <th>NAME</th>\n",
                            "      <th>APPLICATION_TYPE</th>\n",
                            "      <th>AFFILIATION</th>\n",
                            "      <th>CLASSIFICATION</th>\n",
                            "      <th>USE_CASE</th>\n",
                            "      <th>ORGANIZATION</th>\n",
                            "      <th>STATUS</th>\n",
                            "      <th>INCOME_AMT</th>\n",
                            "      <th>SPECIAL_CONSIDERATIONS</th>\n",
                            "      <th>ASK_AMT</th>\n",
                            "      <th>IS_SUCCESSFUL</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>10520599</td>\n",
                            "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
                            "      <td>T10</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C1000</td>\n",
                            "      <td>ProductDev</td>\n",
                            "      <td>Association</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>N</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>10531628</td>\n",
                            "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
                            "      <td>T3</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C2000</td>\n",
                            "      <td>Preservation</td>\n",
                            "      <td>Co-operative</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1-9999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>108590</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>10547893</td>\n",
                            "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
                            "      <td>T5</td>\n",
                            "      <td>CompanySponsored</td>\n",
                            "      <td>C3000</td>\n",
                            "      <td>ProductDev</td>\n",
                            "      <td>Association</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>N</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>10553066</td>\n",
                            "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
                            "      <td>T3</td>\n",
                            "      <td>CompanySponsored</td>\n",
                            "      <td>C2000</td>\n",
                            "      <td>Preservation</td>\n",
                            "      <td>Trust</td>\n",
                            "      <td>1</td>\n",
                            "      <td>10000-24999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>6692</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>10556103</td>\n",
                            "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
                            "      <td>T3</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C1000</td>\n",
                            "      <td>Heathcare</td>\n",
                            "      <td>Trust</td>\n",
                            "      <td>1</td>\n",
                            "      <td>100000-499999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>142590</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        EIN                                      NAME APPLICATION_TYPE  \\\n",
                            "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
                            "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
                            "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
                            "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
                            "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
                            "\n",
                            "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
                            "0       Independent          C1000    ProductDev   Association       1   \n",
                            "1       Independent          C2000  Preservation  Co-operative       1   \n",
                            "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
                            "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
                            "4       Independent          C1000     Heathcare         Trust       1   \n",
                            "\n",
                            "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
                            "0              0                      N     5000              1  \n",
                            "1         1-9999                      N   108590              1  \n",
                            "2              0                      N     5000              0  \n",
                            "3    10000-24999                      N     6692              1  \n",
                            "4  100000-499999                      N   142590              1  "
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Import our dependencies\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "\n",
                "# Import and read the charity_data.csv.\n",
                "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
                "application_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "aa58657a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>APPLICATION_TYPE</th>\n",
                            "      <th>AFFILIATION</th>\n",
                            "      <th>CLASSIFICATION</th>\n",
                            "      <th>USE_CASE</th>\n",
                            "      <th>ORGANIZATION</th>\n",
                            "      <th>STATUS</th>\n",
                            "      <th>INCOME_AMT</th>\n",
                            "      <th>SPECIAL_CONSIDERATIONS</th>\n",
                            "      <th>ASK_AMT</th>\n",
                            "      <th>IS_SUCCESSFUL</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>T10</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C1000</td>\n",
                            "      <td>ProductDev</td>\n",
                            "      <td>Association</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>N</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>T3</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C2000</td>\n",
                            "      <td>Preservation</td>\n",
                            "      <td>Co-operative</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1-9999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>108590</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>T5</td>\n",
                            "      <td>CompanySponsored</td>\n",
                            "      <td>C3000</td>\n",
                            "      <td>ProductDev</td>\n",
                            "      <td>Association</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>N</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>T3</td>\n",
                            "      <td>CompanySponsored</td>\n",
                            "      <td>C2000</td>\n",
                            "      <td>Preservation</td>\n",
                            "      <td>Trust</td>\n",
                            "      <td>1</td>\n",
                            "      <td>10000-24999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>6692</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>T3</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>C1000</td>\n",
                            "      <td>Heathcare</td>\n",
                            "      <td>Trust</td>\n",
                            "      <td>1</td>\n",
                            "      <td>100000-499999</td>\n",
                            "      <td>N</td>\n",
                            "      <td>142590</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
                            "0              T10       Independent          C1000    ProductDev   \n",
                            "1               T3       Independent          C2000  Preservation   \n",
                            "2               T5  CompanySponsored          C3000    ProductDev   \n",
                            "3               T3  CompanySponsored          C2000  Preservation   \n",
                            "4               T3       Independent          C1000     Heathcare   \n",
                            "\n",
                            "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
                            "0   Association       1              0                      N     5000   \n",
                            "1  Co-operative       1         1-9999                      N   108590   \n",
                            "2   Association       1              0                      N     5000   \n",
                            "3         Trust       1    10000-24999                      N     6692   \n",
                            "4         Trust       1  100000-499999                      N   142590   \n",
                            "\n",
                            "   IS_SUCCESSFUL  \n",
                            "0              1  \n",
                            "1              1  \n",
                            "2              0  \n",
                            "3              1  \n",
                            "4              1  "
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'\n",
                "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
                "application_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "id": "e5eba349",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "APPLICATION_TYPE            17\n",
                        "AFFILIATION                  6\n",
                        "CLASSIFICATION              71\n",
                        "USE_CASE                     5\n",
                        "ORGANIZATION                 4\n",
                        "STATUS                       2\n",
                        "INCOME_AMT                   9\n",
                        "SPECIAL_CONSIDERATIONS       2\n",
                        "ASK_AMT                   8747\n",
                        "IS_SUCCESSFUL                2\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Determine the number of unique values in each column\n",
                "unique_values = application_df.nunique()\n",
                "print(unique_values)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "id": "e65c2abb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "APPLICATION_TYPE\n",
                        "T3       27037\n",
                        "T4        1542\n",
                        "T6        1216\n",
                        "T5        1173\n",
                        "T19       1065\n",
                        "T8         737\n",
                        "T7         725\n",
                        "T10        528\n",
                        "Other      276\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Replace rare categorical values in 'APPLICATION_TYPE' with 'Other'\n",
                "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
                "replace_application = list(application_counts[application_counts < 500].index)\n",
                "application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(replace_application, 'Other')\n",
                "print(application_df['APPLICATION_TYPE'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "id": "d5f12fce",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CLASSIFICATION\n",
                        "C1000    17326\n",
                        "C2000     6074\n",
                        "C1200     4837\n",
                        "Other     2261\n",
                        "C3000     1918\n",
                        "C2100     1883\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Replace rare categorical values in 'CLASSIFICATION' with 'Other'\n",
                "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
                "replace_class = list(classification_counts[classification_counts < 1000].index)\n",
                "application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(replace_class, 'Other')\n",
                "print(application_df['CLASSIFICATION'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "id": "ec4ae06a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>STATUS</th>\n",
                            "      <th>ASK_AMT</th>\n",
                            "      <th>IS_SUCCESSFUL</th>\n",
                            "      <th>APPLICATION_TYPE_Other</th>\n",
                            "      <th>APPLICATION_TYPE_T10</th>\n",
                            "      <th>APPLICATION_TYPE_T19</th>\n",
                            "      <th>APPLICATION_TYPE_T3</th>\n",
                            "      <th>APPLICATION_TYPE_T4</th>\n",
                            "      <th>APPLICATION_TYPE_T5</th>\n",
                            "      <th>APPLICATION_TYPE_T6</th>\n",
                            "      <th>...</th>\n",
                            "      <th>INCOME_AMT_1-9999</th>\n",
                            "      <th>INCOME_AMT_10000-24999</th>\n",
                            "      <th>INCOME_AMT_100000-499999</th>\n",
                            "      <th>INCOME_AMT_10M-50M</th>\n",
                            "      <th>INCOME_AMT_1M-5M</th>\n",
                            "      <th>INCOME_AMT_25000-99999</th>\n",
                            "      <th>INCOME_AMT_50M+</th>\n",
                            "      <th>INCOME_AMT_5M-10M</th>\n",
                            "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
                            "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>1</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>...</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>108590</td>\n",
                            "      <td>1</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>...</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5000</td>\n",
                            "      <td>0</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>...</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>6692</td>\n",
                            "      <td>1</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>...</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "      <td>142590</td>\n",
                            "      <td>1</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>...</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 44 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
                            "0       1     5000              1                   False   \n",
                            "1       1   108590              1                   False   \n",
                            "2       1     5000              0                   False   \n",
                            "3       1     6692              1                   False   \n",
                            "4       1   142590              1                   False   \n",
                            "\n",
                            "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
                            "0                  True                 False                False   \n",
                            "1                 False                 False                 True   \n",
                            "2                 False                 False                False   \n",
                            "3                 False                 False                 True   \n",
                            "4                 False                 False                 True   \n",
                            "\n",
                            "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
                            "0                False                False                False  ...   \n",
                            "1                False                False                False  ...   \n",
                            "2                False                 True                False  ...   \n",
                            "3                False                False                False  ...   \n",
                            "4                False                False                False  ...   \n",
                            "\n",
                            "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
                            "0              False                   False                     False   \n",
                            "1               True                   False                     False   \n",
                            "2              False                   False                     False   \n",
                            "3              False                    True                     False   \n",
                            "4              False                   False                      True   \n",
                            "\n",
                            "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
                            "0               False             False                   False   \n",
                            "1               False             False                   False   \n",
                            "2               False             False                   False   \n",
                            "3               False             False                   False   \n",
                            "4               False             False                   False   \n",
                            "\n",
                            "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
                            "0            False              False                      True   \n",
                            "1            False              False                      True   \n",
                            "2            False              False                      True   \n",
                            "3            False              False                      True   \n",
                            "4            False              False                      True   \n",
                            "\n",
                            "   SPECIAL_CONSIDERATIONS_Y  \n",
                            "0                     False  \n",
                            "1                     False  \n",
                            "2                     False  \n",
                            "3                     False  \n",
                            "4                     False  \n",
                            "\n",
                            "[5 rows x 44 columns]"
                        ]
                    },
                    "execution_count": 45,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Convert categorical data to numeric using one-hot encoding\n",
                "application_df_encoded = pd.get_dummies(application_df)\n",
                "application_df_encoded.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "id": "75e1a814",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the preprocessed data into features and target arrays\n",
                "y = application_df_encoded['IS_SUCCESSFUL'].values\n",
                "X = application_df_encoded.drop(columns=['IS_SUCCESSFUL']).values\n",
                "\n",
                "# Split the preprocessed data into training and testing datasets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "id": "87a6ed92",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a StandardScaler instance\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Fit the StandardScaler\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9ec8676b",
            "metadata": {},
            "source": [
                "## Compile, Train, and Evaluate the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "id": "c9baf32b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/dev/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m3,520\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m2,430\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,981</span> (23.36 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,981\u001b[0m (23.36 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,981</span> (23.36 KB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,981\u001b[0m (23.36 KB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Define the model\n",
                "nn = tf.keras.models.Sequential()\n",
                "\n",
                "# First hidden layer\n",
                "nn.add(tf.keras.layers.Dense(units=80, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
                "\n",
                "# Second hidden layer\n",
                "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
                "\n",
                "# Output layer\n",
                "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
                "\n",
                "# Check the structure of the model\n",
                "nn.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "id": "ef3eb3c0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the model\n",
                "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "id": "2f6cca5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom callback to save weights every 5 epochs\n",
                "class CustomCheckpoint(tf.keras.callbacks.Callback):\n",
                "    def __init__(self, save_freq):\n",
                "        super(CustomCheckpoint, self).__init__()\n",
                "        self.save_freq = save_freq\n",
                "\n",
                "    def on_epoch_end(self, epoch, logs=None):\n",
                "        if (epoch + 1) % self.save_freq == 0:\n",
                "            # Correct the file extension to `.weights.h5`\n",
                "            filepath = f'model_weights_epoch_{epoch + 1:02d}.weights.h5'\n",
                "            self.model.save_weights(filepath)\n",
                "            print(f'Saving model weights at epoch {epoch + 1}')\n",
                "\n",
                "# Instantiate the custom callback\n",
                "checkpoint_cb = CustomCheckpoint(save_freq=5)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "id": "f6ce084d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.6992 - loss: 0.5923 - val_accuracy: 0.7380 - val_loss: 0.5492\n",
                        "Epoch 2/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7247 - loss: 0.5600 - val_accuracy: 0.7383 - val_loss: 0.5511\n",
                        "Epoch 3/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7249 - loss: 0.5578 - val_accuracy: 0.7380 - val_loss: 0.5495\n",
                        "Epoch 4/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7299 - loss: 0.5489 - val_accuracy: 0.7396 - val_loss: 0.5485\n",
                        "Epoch 5/100\n",
                        "\u001b[1m685/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7285 - loss: 0.5550Saving model weights at epoch 5\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7286 - loss: 0.5550 - val_accuracy: 0.7363 - val_loss: 0.5493\n",
                        "Epoch 6/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7356 - loss: 0.5465 - val_accuracy: 0.7371 - val_loss: 0.5453\n",
                        "Epoch 7/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7296 - loss: 0.5484 - val_accuracy: 0.7371 - val_loss: 0.5468\n",
                        "Epoch 8/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7361 - loss: 0.5431 - val_accuracy: 0.7371 - val_loss: 0.5500\n",
                        "Epoch 9/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7298 - loss: 0.5466 - val_accuracy: 0.7374 - val_loss: 0.5482\n",
                        "Epoch 10/100\n",
                        "\u001b[1m578/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7338 - loss: 0.5476Saving model weights at epoch 10\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7338 - loss: 0.5475 - val_accuracy: 0.7378 - val_loss: 0.5480\n",
                        "Epoch 11/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7389 - loss: 0.5393 - val_accuracy: 0.7380 - val_loss: 0.5472\n",
                        "Epoch 12/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7354 - loss: 0.5451 - val_accuracy: 0.7391 - val_loss: 0.5442\n",
                        "Epoch 13/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7329 - loss: 0.5457 - val_accuracy: 0.7378 - val_loss: 0.5453\n",
                        "Epoch 14/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7314 - loss: 0.5455 - val_accuracy: 0.7409 - val_loss: 0.5456\n",
                        "Epoch 15/100\n",
                        "\u001b[1m658/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7337 - loss: 0.5398Saving model weights at epoch 15\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7337 - loss: 0.5400 - val_accuracy: 0.7396 - val_loss: 0.5470\n",
                        "Epoch 16/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7305 - loss: 0.5462 - val_accuracy: 0.7378 - val_loss: 0.5435\n",
                        "Epoch 17/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7379 - loss: 0.5403 - val_accuracy: 0.7327 - val_loss: 0.5479\n",
                        "Epoch 18/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7333 - loss: 0.5425 - val_accuracy: 0.7400 - val_loss: 0.5458\n",
                        "Epoch 19/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7359 - loss: 0.5414 - val_accuracy: 0.7362 - val_loss: 0.5469\n",
                        "Epoch 20/100\n",
                        "\u001b[1m636/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7354 - loss: 0.5415Saving model weights at epoch 20\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7354 - loss: 0.5417 - val_accuracy: 0.7392 - val_loss: 0.5434\n",
                        "Epoch 21/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7340 - loss: 0.5430 - val_accuracy: 0.7360 - val_loss: 0.5470\n",
                        "Epoch 22/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7334 - loss: 0.5442 - val_accuracy: 0.7380 - val_loss: 0.5478\n",
                        "Epoch 23/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7314 - loss: 0.5473 - val_accuracy: 0.7365 - val_loss: 0.5465\n",
                        "Epoch 24/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7269 - loss: 0.5488 - val_accuracy: 0.7411 - val_loss: 0.5438\n",
                        "Epoch 25/100\n",
                        "\u001b[1m635/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7409 - loss: 0.5356Saving model weights at epoch 25\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7404 - loss: 0.5361 - val_accuracy: 0.7360 - val_loss: 0.5466\n",
                        "Epoch 26/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7342 - loss: 0.5385 - val_accuracy: 0.7385 - val_loss: 0.5480\n",
                        "Epoch 27/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7404 - loss: 0.5339 - val_accuracy: 0.7387 - val_loss: 0.5466\n",
                        "Epoch 28/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7348 - loss: 0.5393 - val_accuracy: 0.7392 - val_loss: 0.5449\n",
                        "Epoch 29/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7314 - loss: 0.5415 - val_accuracy: 0.7391 - val_loss: 0.5454\n",
                        "Epoch 30/100\n",
                        "\u001b[1m534/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7325 - loss: 0.5459Saving model weights at epoch 30\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7330 - loss: 0.5451 - val_accuracy: 0.7396 - val_loss: 0.5463\n",
                        "Epoch 31/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7341 - loss: 0.5420 - val_accuracy: 0.7367 - val_loss: 0.5479\n",
                        "Epoch 32/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7332 - loss: 0.5434 - val_accuracy: 0.7396 - val_loss: 0.5447\n",
                        "Epoch 33/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7319 - loss: 0.5403 - val_accuracy: 0.7422 - val_loss: 0.5491\n",
                        "Epoch 34/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7334 - loss: 0.5419 - val_accuracy: 0.7391 - val_loss: 0.5455\n",
                        "Epoch 35/100\n",
                        "\u001b[1m682/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7372 - loss: 0.5375Saving model weights at epoch 35\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7372 - loss: 0.5375 - val_accuracy: 0.7391 - val_loss: 0.5475\n",
                        "Epoch 36/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7350 - loss: 0.5438 - val_accuracy: 0.7383 - val_loss: 0.5458\n",
                        "Epoch 37/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7412 - loss: 0.5353 - val_accuracy: 0.7383 - val_loss: 0.5442\n",
                        "Epoch 38/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7363 - loss: 0.5419 - val_accuracy: 0.7372 - val_loss: 0.5497\n",
                        "Epoch 39/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7401 - loss: 0.5378 - val_accuracy: 0.7383 - val_loss: 0.5453\n",
                        "Epoch 40/100\n",
                        "\u001b[1m649/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7402 - loss: 0.5337Saving model weights at epoch 40\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7400 - loss: 0.5340 - val_accuracy: 0.7387 - val_loss: 0.5443\n",
                        "Epoch 41/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7380 - loss: 0.5355 - val_accuracy: 0.7382 - val_loss: 0.5446\n",
                        "Epoch 42/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7409 - loss: 0.5332 - val_accuracy: 0.7383 - val_loss: 0.5464\n",
                        "Epoch 43/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7378 - loss: 0.5342 - val_accuracy: 0.7391 - val_loss: 0.5501\n",
                        "Epoch 44/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7350 - loss: 0.5398 - val_accuracy: 0.7383 - val_loss: 0.5462\n",
                        "Epoch 45/100\n",
                        "\u001b[1m586/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7361 - loss: 0.5401Saving model weights at epoch 45\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7363 - loss: 0.5398 - val_accuracy: 0.7380 - val_loss: 0.5467\n",
                        "Epoch 46/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7384 - loss: 0.5360 - val_accuracy: 0.7385 - val_loss: 0.5502\n",
                        "Epoch 47/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7345 - loss: 0.5398 - val_accuracy: 0.7396 - val_loss: 0.5457\n",
                        "Epoch 48/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7427 - loss: 0.5337 - val_accuracy: 0.7382 - val_loss: 0.5485\n",
                        "Epoch 49/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7349 - loss: 0.5379 - val_accuracy: 0.7372 - val_loss: 0.5462\n",
                        "Epoch 50/100\n",
                        "\u001b[1m513/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7388 - loss: 0.5363Saving model weights at epoch 50\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7385 - loss: 0.5366 - val_accuracy: 0.7371 - val_loss: 0.5472\n",
                        "Epoch 51/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7365 - loss: 0.5404 - val_accuracy: 0.7367 - val_loss: 0.5489\n",
                        "Epoch 52/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7381 - loss: 0.5346 - val_accuracy: 0.7391 - val_loss: 0.5470\n",
                        "Epoch 53/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7361 - loss: 0.5360 - val_accuracy: 0.7378 - val_loss: 0.5457\n",
                        "Epoch 54/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7362 - loss: 0.5397 - val_accuracy: 0.7374 - val_loss: 0.5468\n",
                        "Epoch 55/100\n",
                        "\u001b[1m583/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7426 - loss: 0.5342Saving model weights at epoch 55\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7419 - loss: 0.5348 - val_accuracy: 0.7367 - val_loss: 0.5494\n",
                        "Epoch 56/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7366 - loss: 0.5395 - val_accuracy: 0.7378 - val_loss: 0.5458\n",
                        "Epoch 57/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7407 - loss: 0.5326 - val_accuracy: 0.7394 - val_loss: 0.5463\n",
                        "Epoch 58/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7404 - loss: 0.5335 - val_accuracy: 0.7398 - val_loss: 0.5485\n",
                        "Epoch 59/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7383 - loss: 0.5369 - val_accuracy: 0.7402 - val_loss: 0.5479\n",
                        "Epoch 60/100\n",
                        "\u001b[1m664/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7370 - loss: 0.5381Saving model weights at epoch 60\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7370 - loss: 0.5380 - val_accuracy: 0.7383 - val_loss: 0.5459\n",
                        "Epoch 61/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7417 - loss: 0.5314 - val_accuracy: 0.7383 - val_loss: 0.5474\n",
                        "Epoch 62/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7320 - loss: 0.5417 - val_accuracy: 0.7396 - val_loss: 0.5512\n",
                        "Epoch 63/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7381 - loss: 0.5385 - val_accuracy: 0.7400 - val_loss: 0.5499\n",
                        "Epoch 64/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7392 - loss: 0.5367 - val_accuracy: 0.7389 - val_loss: 0.5504\n",
                        "Epoch 65/100\n",
                        "\u001b[1m515/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7384 - loss: 0.5335Saving model weights at epoch 65\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7382 - loss: 0.5341 - val_accuracy: 0.7391 - val_loss: 0.5463\n",
                        "Epoch 66/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7380 - loss: 0.5364 - val_accuracy: 0.7403 - val_loss: 0.5488\n",
                        "Epoch 67/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7369 - loss: 0.5333 - val_accuracy: 0.7405 - val_loss: 0.5472\n",
                        "Epoch 68/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7392 - loss: 0.5346 - val_accuracy: 0.7394 - val_loss: 0.5517\n",
                        "Epoch 69/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7400 - loss: 0.5334 - val_accuracy: 0.7396 - val_loss: 0.5484\n",
                        "Epoch 70/100\n",
                        "\u001b[1m670/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7372 - loss: 0.5344Saving model weights at epoch 70\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7372 - loss: 0.5344 - val_accuracy: 0.7391 - val_loss: 0.5486\n",
                        "Epoch 71/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7391 - loss: 0.5355 - val_accuracy: 0.7394 - val_loss: 0.5539\n",
                        "Epoch 72/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7368 - loss: 0.5370 - val_accuracy: 0.7376 - val_loss: 0.5520\n",
                        "Epoch 73/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7384 - loss: 0.5392 - val_accuracy: 0.7391 - val_loss: 0.5525\n",
                        "Epoch 74/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7388 - loss: 0.5339 - val_accuracy: 0.7396 - val_loss: 0.5499\n",
                        "Epoch 75/100\n",
                        "\u001b[1m683/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7429 - loss: 0.5268Saving model weights at epoch 75\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7428 - loss: 0.5268 - val_accuracy: 0.7389 - val_loss: 0.5504\n",
                        "Epoch 76/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7378 - loss: 0.5342 - val_accuracy: 0.7365 - val_loss: 0.5479\n",
                        "Epoch 77/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7371 - loss: 0.5343 - val_accuracy: 0.7376 - val_loss: 0.5490\n",
                        "Epoch 78/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7369 - loss: 0.5378 - val_accuracy: 0.7378 - val_loss: 0.5494\n",
                        "Epoch 79/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7358 - loss: 0.5376 - val_accuracy: 0.7400 - val_loss: 0.5521\n",
                        "Epoch 80/100\n",
                        "\u001b[1m594/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7391 - loss: 0.5337Saving model weights at epoch 80\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7390 - loss: 0.5340 - val_accuracy: 0.7389 - val_loss: 0.5537\n",
                        "Epoch 81/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7405 - loss: 0.5330 - val_accuracy: 0.7380 - val_loss: 0.5516\n",
                        "Epoch 82/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7342 - loss: 0.5399 - val_accuracy: 0.7369 - val_loss: 0.5502\n",
                        "Epoch 83/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7380 - loss: 0.5329 - val_accuracy: 0.7385 - val_loss: 0.5533\n",
                        "Epoch 84/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7415 - loss: 0.5316 - val_accuracy: 0.7378 - val_loss: 0.5557\n",
                        "Epoch 85/100\n",
                        "\u001b[1m516/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7275 - loss: 0.5437Saving model weights at epoch 85\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.7299 - loss: 0.5416 - val_accuracy: 0.7389 - val_loss: 0.5518\n",
                        "Epoch 86/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7404 - loss: 0.5286 - val_accuracy: 0.7382 - val_loss: 0.5534\n",
                        "Epoch 87/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7391 - loss: 0.5354 - val_accuracy: 0.7396 - val_loss: 0.5508\n",
                        "Epoch 88/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7412 - loss: 0.5324 - val_accuracy: 0.7403 - val_loss: 0.5550\n",
                        "Epoch 89/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7369 - loss: 0.5336 - val_accuracy: 0.7383 - val_loss: 0.5524\n",
                        "Epoch 90/100\n",
                        "\u001b[1m662/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7391 - loss: 0.5335Saving model weights at epoch 90\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7390 - loss: 0.5336 - val_accuracy: 0.7398 - val_loss: 0.5514\n",
                        "Epoch 91/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7379 - loss: 0.5369 - val_accuracy: 0.7396 - val_loss: 0.5530\n",
                        "Epoch 92/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7378 - loss: 0.5349 - val_accuracy: 0.7387 - val_loss: 0.5522\n",
                        "Epoch 93/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7394 - loss: 0.5332 - val_accuracy: 0.7387 - val_loss: 0.5534\n",
                        "Epoch 94/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7414 - loss: 0.5328 - val_accuracy: 0.7391 - val_loss: 0.5514\n",
                        "Epoch 95/100\n",
                        "\u001b[1m594/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7408 - loss: 0.5339Saving model weights at epoch 95\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7407 - loss: 0.5338 - val_accuracy: 0.7389 - val_loss: 0.5533\n",
                        "Epoch 96/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7358 - loss: 0.5363 - val_accuracy: 0.7400 - val_loss: 0.5528\n",
                        "Epoch 97/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7415 - loss: 0.5337 - val_accuracy: 0.7405 - val_loss: 0.5517\n",
                        "Epoch 98/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7402 - loss: 0.5328 - val_accuracy: 0.7400 - val_loss: 0.5519\n",
                        "Epoch 99/100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7387 - loss: 0.5326 - val_accuracy: 0.7400 - val_loss: 0.5522\n",
                        "Epoch 100/100\n",
                        "\u001b[1m683/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7373 - loss: 0.5342Saving model weights at epoch 100\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7373 - loss: 0.5342 - val_accuracy: 0.7402 - val_loss: 0.5546\n"
                    ]
                }
            ],
            "source": [
                "# Train the model with custom checkpoint callback\n",
                "history = nn.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[checkpoint_cb])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "id": "6bf38382",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "215/215 - 0s - 400us/step - accuracy: 0.7270 - loss: 0.5687\n",
                        "Loss: 0.5687134265899658, Accuracy: 0.7269679307937622\n"
                    ]
                }
            ],
            "source": [
                "# Evaluate the model using the test data\n",
                "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
                "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "id": "0452966d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
                    ]
                }
            ],
            "source": [
                "# Export the model to an HDF5 file\n",
                "nn.save('AlphabetSoupCharity.h5')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "109452bf",
            "metadata": {},
            "source": [
                "## Step 3: Optimize the Model #1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "id": "f2d2dac4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.6974 - loss: 0.5922 - val_accuracy: 0.7376 - val_loss: 0.5483\n",
                        "Epoch 2/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7209 - loss: 0.5637 - val_accuracy: 0.7378 - val_loss: 0.5531\n",
                        "Epoch 3/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7324 - loss: 0.5462 - val_accuracy: 0.7382 - val_loss: 0.5516\n",
                        "Epoch 4/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7306 - loss: 0.5486 - val_accuracy: 0.7349 - val_loss: 0.5506\n",
                        "Epoch 5/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7337 - loss: 0.5464 - val_accuracy: 0.7358 - val_loss: 0.5505\n",
                        "Epoch 6/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.7294 - loss: 0.5481 - val_accuracy: 0.7396 - val_loss: 0.5454\n",
                        "Epoch 7/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7241 - loss: 0.5511 - val_accuracy: 0.7387 - val_loss: 0.5443\n",
                        "Epoch 8/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7373 - loss: 0.5410 - val_accuracy: 0.7380 - val_loss: 0.5451\n",
                        "Epoch 9/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7337 - loss: 0.5453 - val_accuracy: 0.7380 - val_loss: 0.5492\n",
                        "Epoch 10/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7332 - loss: 0.5460 - val_accuracy: 0.7387 - val_loss: 0.5473\n",
                        "Epoch 11/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7297 - loss: 0.5451 - val_accuracy: 0.7392 - val_loss: 0.5451\n",
                        "Epoch 12/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7356 - loss: 0.5418 - val_accuracy: 0.7369 - val_loss: 0.5475\n",
                        "Epoch 13/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7334 - loss: 0.5476 - val_accuracy: 0.7385 - val_loss: 0.5448\n",
                        "Epoch 14/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7332 - loss: 0.5437 - val_accuracy: 0.7394 - val_loss: 0.5450\n",
                        "Epoch 15/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7365 - loss: 0.5417 - val_accuracy: 0.7369 - val_loss: 0.5456\n",
                        "Epoch 16/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7346 - loss: 0.5404 - val_accuracy: 0.7407 - val_loss: 0.5444\n",
                        "Epoch 17/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7326 - loss: 0.5421 - val_accuracy: 0.7356 - val_loss: 0.5450\n",
                        "Epoch 18/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7366 - loss: 0.5389 - val_accuracy: 0.7396 - val_loss: 0.5461\n",
                        "Epoch 19/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7372 - loss: 0.5403 - val_accuracy: 0.7383 - val_loss: 0.5431\n",
                        "Epoch 20/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7349 - loss: 0.5416 - val_accuracy: 0.7387 - val_loss: 0.5447\n",
                        "Epoch 21/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7350 - loss: 0.5440 - val_accuracy: 0.7387 - val_loss: 0.5444\n",
                        "Epoch 22/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7358 - loss: 0.5403 - val_accuracy: 0.7389 - val_loss: 0.5423\n",
                        "Epoch 23/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7332 - loss: 0.5416 - val_accuracy: 0.7396 - val_loss: 0.5443\n",
                        "Epoch 24/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7351 - loss: 0.5410 - val_accuracy: 0.7402 - val_loss: 0.5446\n",
                        "Epoch 25/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7393 - loss: 0.5340 - val_accuracy: 0.7387 - val_loss: 0.5454\n",
                        "Epoch 26/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7437 - loss: 0.5339 - val_accuracy: 0.7362 - val_loss: 0.5477\n",
                        "Epoch 27/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7350 - loss: 0.5411 - val_accuracy: 0.7372 - val_loss: 0.5463\n",
                        "Epoch 28/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7383 - loss: 0.5379 - val_accuracy: 0.7383 - val_loss: 0.5462\n",
                        "Epoch 29/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7316 - loss: 0.5418 - val_accuracy: 0.7365 - val_loss: 0.5456\n",
                        "Epoch 30/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7394 - loss: 0.5370 - val_accuracy: 0.7394 - val_loss: 0.5464\n",
                        "Epoch 31/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7356 - loss: 0.5396 - val_accuracy: 0.7372 - val_loss: 0.5449\n",
                        "Epoch 32/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7397 - loss: 0.5352 - val_accuracy: 0.7374 - val_loss: 0.5434\n",
                        "Epoch 33/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7392 - loss: 0.5385 - val_accuracy: 0.7378 - val_loss: 0.5457\n",
                        "Epoch 34/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7336 - loss: 0.5429 - val_accuracy: 0.7382 - val_loss: 0.5465\n",
                        "Epoch 35/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7388 - loss: 0.5342 - val_accuracy: 0.7389 - val_loss: 0.5487\n",
                        "Epoch 36/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7408 - loss: 0.5336 - val_accuracy: 0.7367 - val_loss: 0.5489\n",
                        "Epoch 37/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7369 - loss: 0.5381 - val_accuracy: 0.7372 - val_loss: 0.5495\n",
                        "Epoch 38/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7372 - loss: 0.5358 - val_accuracy: 0.7376 - val_loss: 0.5465\n",
                        "Epoch 39/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7387 - loss: 0.5376 - val_accuracy: 0.7385 - val_loss: 0.5466\n",
                        "Epoch 40/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7378 - loss: 0.5373 - val_accuracy: 0.7394 - val_loss: 0.5477\n",
                        "Epoch 41/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7339 - loss: 0.5379 - val_accuracy: 0.7372 - val_loss: 0.5434\n",
                        "Epoch 42/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7360 - loss: 0.5384 - val_accuracy: 0.7382 - val_loss: 0.5498\n",
                        "Epoch 43/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7344 - loss: 0.5383 - val_accuracy: 0.7405 - val_loss: 0.5451\n",
                        "Epoch 44/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7327 - loss: 0.5430 - val_accuracy: 0.7389 - val_loss: 0.5487\n",
                        "Epoch 45/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7377 - loss: 0.5341 - val_accuracy: 0.7402 - val_loss: 0.5470\n",
                        "Epoch 46/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7383 - loss: 0.5374 - val_accuracy: 0.7405 - val_loss: 0.5502\n",
                        "Epoch 47/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7368 - loss: 0.5395 - val_accuracy: 0.7382 - val_loss: 0.5488\n",
                        "Epoch 48/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7370 - loss: 0.5340 - val_accuracy: 0.7383 - val_loss: 0.5495\n",
                        "Epoch 49/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7407 - loss: 0.5321 - val_accuracy: 0.7392 - val_loss: 0.5474\n",
                        "Epoch 50/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7345 - loss: 0.5363 - val_accuracy: 0.7398 - val_loss: 0.5464\n",
                        "Epoch 51/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7372 - loss: 0.5375 - val_accuracy: 0.7402 - val_loss: 0.5494\n",
                        "Epoch 52/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7395 - loss: 0.5325 - val_accuracy: 0.7400 - val_loss: 0.5461\n",
                        "Epoch 53/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7442 - loss: 0.5306 - val_accuracy: 0.7387 - val_loss: 0.5508\n",
                        "Epoch 54/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7395 - loss: 0.5319 - val_accuracy: 0.7398 - val_loss: 0.5485\n",
                        "Epoch 55/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7327 - loss: 0.5409 - val_accuracy: 0.7398 - val_loss: 0.5494\n",
                        "Epoch 56/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7391 - loss: 0.5332 - val_accuracy: 0.7394 - val_loss: 0.5476\n",
                        "Epoch 57/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7400 - loss: 0.5354 - val_accuracy: 0.7394 - val_loss: 0.5519\n",
                        "Epoch 58/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7416 - loss: 0.5317 - val_accuracy: 0.7378 - val_loss: 0.5473\n",
                        "Epoch 59/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7396 - loss: 0.5318 - val_accuracy: 0.7389 - val_loss: 0.5503\n",
                        "Epoch 60/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7372 - loss: 0.5367 - val_accuracy: 0.7407 - val_loss: 0.5515\n",
                        "Epoch 61/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7363 - loss: 0.5364 - val_accuracy: 0.7392 - val_loss: 0.5528\n",
                        "Epoch 62/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7424 - loss: 0.5305 - val_accuracy: 0.7405 - val_loss: 0.5495\n",
                        "Epoch 63/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7411 - loss: 0.5298 - val_accuracy: 0.7400 - val_loss: 0.5507\n",
                        "Epoch 64/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7391 - loss: 0.5338 - val_accuracy: 0.7394 - val_loss: 0.5531\n",
                        "Epoch 65/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7401 - loss: 0.5366 - val_accuracy: 0.7372 - val_loss: 0.5543\n",
                        "Epoch 66/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7382 - loss: 0.5364 - val_accuracy: 0.7383 - val_loss: 0.5512\n",
                        "Epoch 67/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7406 - loss: 0.5353 - val_accuracy: 0.7380 - val_loss: 0.5528\n",
                        "Epoch 68/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7419 - loss: 0.5309 - val_accuracy: 0.7380 - val_loss: 0.5576\n",
                        "Epoch 69/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7366 - loss: 0.5362 - val_accuracy: 0.7387 - val_loss: 0.5560\n",
                        "Epoch 70/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7373 - loss: 0.5327 - val_accuracy: 0.7382 - val_loss: 0.5547\n",
                        "Epoch 71/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7407 - loss: 0.5327 - val_accuracy: 0.7372 - val_loss: 0.5553\n",
                        "Epoch 72/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7388 - loss: 0.5321 - val_accuracy: 0.7396 - val_loss: 0.5560\n",
                        "Epoch 73/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7336 - loss: 0.5381 - val_accuracy: 0.7396 - val_loss: 0.5559\n",
                        "Epoch 74/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7391 - loss: 0.5339 - val_accuracy: 0.7383 - val_loss: 0.5582\n",
                        "Epoch 75/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7379 - loss: 0.5343 - val_accuracy: 0.7383 - val_loss: 0.5544\n",
                        "Epoch 76/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7416 - loss: 0.5292 - val_accuracy: 0.7385 - val_loss: 0.5521\n",
                        "Epoch 77/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7354 - loss: 0.5352 - val_accuracy: 0.7387 - val_loss: 0.5535\n",
                        "Epoch 78/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7444 - loss: 0.5270 - val_accuracy: 0.7392 - val_loss: 0.5590\n",
                        "Epoch 79/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7357 - loss: 0.5361 - val_accuracy: 0.7407 - val_loss: 0.5533\n",
                        "Epoch 80/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7408 - loss: 0.5326 - val_accuracy: 0.7394 - val_loss: 0.5548\n",
                        "Epoch 81/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7411 - loss: 0.5304 - val_accuracy: 0.7380 - val_loss: 0.5567\n",
                        "Epoch 82/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7357 - loss: 0.5357 - val_accuracy: 0.7365 - val_loss: 0.5573\n",
                        "Epoch 83/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7446 - loss: 0.5283 - val_accuracy: 0.7382 - val_loss: 0.5602\n",
                        "Epoch 84/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7378 - loss: 0.5355 - val_accuracy: 0.7378 - val_loss: 0.5593\n",
                        "Epoch 85/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7380 - loss: 0.5332 - val_accuracy: 0.7396 - val_loss: 0.5607\n",
                        "Epoch 86/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7424 - loss: 0.5306 - val_accuracy: 0.7376 - val_loss: 0.5603\n",
                        "Epoch 87/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7368 - loss: 0.5343 - val_accuracy: 0.7372 - val_loss: 0.5563\n",
                        "Epoch 88/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7357 - loss: 0.5387 - val_accuracy: 0.7385 - val_loss: 0.5675\n",
                        "Epoch 89/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7394 - loss: 0.5307 - val_accuracy: 0.7376 - val_loss: 0.5564\n",
                        "Epoch 90/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7375 - loss: 0.5363 - val_accuracy: 0.7380 - val_loss: 0.5572\n",
                        "Epoch 91/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7411 - loss: 0.5316 - val_accuracy: 0.7385 - val_loss: 0.5645\n",
                        "Epoch 92/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7372 - loss: 0.5360 - val_accuracy: 0.7374 - val_loss: 0.5694\n",
                        "Epoch 93/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7417 - loss: 0.5271 - val_accuracy: 0.7391 - val_loss: 0.5644\n",
                        "Epoch 94/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7422 - loss: 0.5314 - val_accuracy: 0.7382 - val_loss: 0.5631\n",
                        "Epoch 95/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7371 - loss: 0.5352 - val_accuracy: 0.7380 - val_loss: 0.5688\n",
                        "Epoch 96/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7391 - loss: 0.5320 - val_accuracy: 0.7382 - val_loss: 0.5652\n",
                        "Epoch 97/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7414 - loss: 0.5340 - val_accuracy: 0.7367 - val_loss: 0.5640\n",
                        "Epoch 98/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7405 - loss: 0.5306 - val_accuracy: 0.7376 - val_loss: 0.5645\n",
                        "Epoch 99/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7435 - loss: 0.5291 - val_accuracy: 0.7376 - val_loss: 0.5593\n",
                        "Epoch 100/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7426 - loss: 0.5320 - val_accuracy: 0.7392 - val_loss: 0.5672\n",
                        "Epoch 101/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7378 - loss: 0.5332 - val_accuracy: 0.7378 - val_loss: 0.5647\n",
                        "Epoch 102/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7398 - loss: 0.5273 - val_accuracy: 0.7380 - val_loss: 0.5626\n",
                        "Epoch 103/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7391 - loss: 0.5298 - val_accuracy: 0.7396 - val_loss: 0.5650\n",
                        "Epoch 104/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7411 - loss: 0.5309 - val_accuracy: 0.7369 - val_loss: 0.5657\n",
                        "Epoch 105/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7440 - loss: 0.5289 - val_accuracy: 0.7376 - val_loss: 0.5644\n",
                        "Epoch 106/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7392 - loss: 0.5325 - val_accuracy: 0.7391 - val_loss: 0.5694\n",
                        "Epoch 107/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7426 - loss: 0.5289 - val_accuracy: 0.7369 - val_loss: 0.5665\n",
                        "Epoch 108/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7362 - loss: 0.5358 - val_accuracy: 0.7378 - val_loss: 0.5604\n",
                        "Epoch 109/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7385 - loss: 0.5381 - val_accuracy: 0.7367 - val_loss: 0.5774\n",
                        "Epoch 110/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7388 - loss: 0.5331 - val_accuracy: 0.7382 - val_loss: 0.5670\n",
                        "Epoch 111/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7427 - loss: 0.5289 - val_accuracy: 0.7382 - val_loss: 0.5650\n",
                        "Epoch 112/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7440 - loss: 0.5276 - val_accuracy: 0.7383 - val_loss: 0.5702\n",
                        "Epoch 113/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7416 - loss: 0.5311 - val_accuracy: 0.7380 - val_loss: 0.5690\n",
                        "Epoch 114/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7384 - loss: 0.5331 - val_accuracy: 0.7376 - val_loss: 0.5803\n",
                        "Epoch 115/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7374 - loss: 0.5336 - val_accuracy: 0.7378 - val_loss: 0.5702\n",
                        "Epoch 116/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7440 - loss: 0.5265 - val_accuracy: 0.7376 - val_loss: 0.5741\n",
                        "Epoch 117/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7373 - loss: 0.5340 - val_accuracy: 0.7382 - val_loss: 0.5752\n",
                        "Epoch 118/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.7417 - loss: 0.5308 - val_accuracy: 0.7371 - val_loss: 0.5685\n",
                        "Epoch 119/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7428 - loss: 0.5260 - val_accuracy: 0.7380 - val_loss: 0.5716\n",
                        "Epoch 120/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7364 - loss: 0.5335 - val_accuracy: 0.7387 - val_loss: 0.5689\n",
                        "Epoch 121/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7355 - loss: 0.5316 - val_accuracy: 0.7382 - val_loss: 0.5790\n",
                        "Epoch 122/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7385 - loss: 0.5327 - val_accuracy: 0.7383 - val_loss: 0.5668\n",
                        "Epoch 123/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7447 - loss: 0.5282 - val_accuracy: 0.7358 - val_loss: 0.5794\n",
                        "Epoch 124/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7368 - loss: 0.5362 - val_accuracy: 0.7383 - val_loss: 0.5752\n",
                        "Epoch 125/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7413 - loss: 0.5317 - val_accuracy: 0.7382 - val_loss: 0.5673\n",
                        "Epoch 126/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7395 - loss: 0.5352 - val_accuracy: 0.7371 - val_loss: 0.5760\n",
                        "Epoch 127/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.7392 - loss: 0.5280 - val_accuracy: 0.7382 - val_loss: 0.5782\n",
                        "Epoch 128/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7378 - loss: 0.5339 - val_accuracy: 0.7392 - val_loss: 0.5872\n",
                        "Epoch 129/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7369 - loss: 0.5332 - val_accuracy: 0.7371 - val_loss: 0.5830\n",
                        "Epoch 130/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7380 - loss: 0.5331 - val_accuracy: 0.7380 - val_loss: 0.5812\n",
                        "Epoch 131/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7386 - loss: 0.5295 - val_accuracy: 0.7369 - val_loss: 0.5770\n",
                        "Epoch 132/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7402 - loss: 0.5311 - val_accuracy: 0.7383 - val_loss: 0.5748\n",
                        "Epoch 133/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7415 - loss: 0.5287 - val_accuracy: 0.7374 - val_loss: 0.5816\n",
                        "Epoch 134/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7405 - loss: 0.5308 - val_accuracy: 0.7380 - val_loss: 0.5841\n",
                        "Epoch 135/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7422 - loss: 0.5323 - val_accuracy: 0.7376 - val_loss: 0.5834\n",
                        "Epoch 136/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7350 - loss: 0.5366 - val_accuracy: 0.7382 - val_loss: 0.5824\n",
                        "Epoch 137/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7435 - loss: 0.5246 - val_accuracy: 0.7365 - val_loss: 0.5879\n",
                        "Epoch 138/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7386 - loss: 0.5340 - val_accuracy: 0.7383 - val_loss: 0.5775\n",
                        "Epoch 139/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7395 - loss: 0.5322 - val_accuracy: 0.7372 - val_loss: 0.5805\n",
                        "Epoch 140/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7363 - loss: 0.5344 - val_accuracy: 0.7374 - val_loss: 0.5738\n",
                        "Epoch 141/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7343 - loss: 0.5344 - val_accuracy: 0.7378 - val_loss: 0.5887\n",
                        "Epoch 142/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.7361 - loss: 0.5315 - val_accuracy: 0.7391 - val_loss: 0.5847\n",
                        "Epoch 143/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7432 - loss: 0.5280 - val_accuracy: 0.7387 - val_loss: 0.5856\n",
                        "Epoch 144/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7405 - loss: 0.5302 - val_accuracy: 0.7391 - val_loss: 0.5836\n",
                        "Epoch 145/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7426 - loss: 0.5299 - val_accuracy: 0.7383 - val_loss: 0.5924\n",
                        "Epoch 146/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7374 - loss: 0.5349 - val_accuracy: 0.7380 - val_loss: 0.5924\n",
                        "Epoch 147/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7378 - loss: 0.5350 - val_accuracy: 0.7383 - val_loss: 0.5752\n",
                        "Epoch 148/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7407 - loss: 0.5282 - val_accuracy: 0.7378 - val_loss: 0.5714\n",
                        "Epoch 149/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7418 - loss: 0.5297 - val_accuracy: 0.7389 - val_loss: 0.5789\n",
                        "Epoch 150/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7384 - loss: 0.5310 - val_accuracy: 0.7394 - val_loss: 0.5797\n",
                        "215/215 - 0s - 268us/step - accuracy: 0.7252 - loss: 0.5992\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized Loss: 0.5991957783699036, Optimized Accuracy: 0.725218653678894\n"
                    ]
                }
            ],
            "source": [
                "# Model Optimization - Attempt 1: Add another hidden layer\n",
                "nn_opt = tf.keras.models.Sequential()\n",
                "\n",
                "# Add more neurons and an additional hidden layer\n",
                "nn_opt.add(tf.keras.layers.Dense(units=100, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
                "nn_opt.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
                "nn_opt.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
                "nn_opt.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
                "\n",
                "# Compile the optimized model\n",
                "nn_opt.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Train the optimized model\n",
                "history_opt = nn_opt.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2)\n",
                "\n",
                "# Evaluate the optimized model\n",
                "model_loss_opt, model_accuracy_opt = nn_opt.evaluate(X_test_scaled, y_test, verbose=2)\n",
                "print(f\"Optimized Loss: {model_loss_opt}, Optimized Accuracy: {model_accuracy_opt}\")\n",
                "\n",
                "# Save the optimized model\n",
                "nn_opt.save('AlphabetSoupCharity_Optimization.h5')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "786441d6",
            "metadata": {},
            "source": [
                "Optimize Model #2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "id": "9fcdcf75",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.7127 - loss: 0.5830 - val_accuracy: 0.7362 - val_loss: 0.5508\n",
                        "Epoch 2/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7275 - loss: 0.5558 - val_accuracy: 0.7374 - val_loss: 0.5534\n",
                        "Epoch 3/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7306 - loss: 0.5552 - val_accuracy: 0.7376 - val_loss: 0.5462\n",
                        "Epoch 4/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7301 - loss: 0.5536 - val_accuracy: 0.7298 - val_loss: 0.5494\n",
                        "Epoch 5/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7315 - loss: 0.5473 - val_accuracy: 0.7403 - val_loss: 0.5450\n",
                        "Epoch 6/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7295 - loss: 0.5502 - val_accuracy: 0.7396 - val_loss: 0.5445\n",
                        "Epoch 7/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7289 - loss: 0.5471 - val_accuracy: 0.7383 - val_loss: 0.5445\n",
                        "Epoch 8/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7339 - loss: 0.5446 - val_accuracy: 0.7385 - val_loss: 0.5433\n",
                        "Epoch 9/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7365 - loss: 0.5414 - val_accuracy: 0.7380 - val_loss: 0.5430\n",
                        "Epoch 10/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7372 - loss: 0.5419 - val_accuracy: 0.7398 - val_loss: 0.5424\n",
                        "Epoch 11/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.7375 - loss: 0.5432 - val_accuracy: 0.7378 - val_loss: 0.5433\n",
                        "Epoch 12/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.7331 - loss: 0.5430 - val_accuracy: 0.7389 - val_loss: 0.5434\n",
                        "Epoch 13/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7360 - loss: 0.5433 - val_accuracy: 0.7345 - val_loss: 0.5429\n",
                        "Epoch 14/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7295 - loss: 0.5439 - val_accuracy: 0.7383 - val_loss: 0.5426\n",
                        "Epoch 15/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.7416 - loss: 0.5347 - val_accuracy: 0.7378 - val_loss: 0.5410\n",
                        "Epoch 16/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7360 - loss: 0.5402 - val_accuracy: 0.7367 - val_loss: 0.5442\n",
                        "Epoch 17/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7394 - loss: 0.5368 - val_accuracy: 0.7374 - val_loss: 0.5438\n",
                        "Epoch 18/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7325 - loss: 0.5450 - val_accuracy: 0.7380 - val_loss: 0.5437\n",
                        "Epoch 19/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7362 - loss: 0.5376 - val_accuracy: 0.7376 - val_loss: 0.5444\n",
                        "Epoch 20/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7381 - loss: 0.5380 - val_accuracy: 0.7396 - val_loss: 0.5417\n",
                        "Epoch 21/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7382 - loss: 0.5366 - val_accuracy: 0.7402 - val_loss: 0.5420\n",
                        "Epoch 22/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7322 - loss: 0.5430 - val_accuracy: 0.7367 - val_loss: 0.5448\n",
                        "Epoch 23/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7366 - loss: 0.5407 - val_accuracy: 0.7380 - val_loss: 0.5442\n",
                        "Epoch 24/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7377 - loss: 0.5365 - val_accuracy: 0.7369 - val_loss: 0.5449\n",
                        "Epoch 25/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7365 - loss: 0.5378 - val_accuracy: 0.7378 - val_loss: 0.5458\n",
                        "Epoch 26/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7366 - loss: 0.5355 - val_accuracy: 0.7382 - val_loss: 0.5463\n",
                        "Epoch 27/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7336 - loss: 0.5400 - val_accuracy: 0.7392 - val_loss: 0.5443\n",
                        "Epoch 28/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7363 - loss: 0.5358 - val_accuracy: 0.7380 - val_loss: 0.5444\n",
                        "Epoch 29/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7395 - loss: 0.5351 - val_accuracy: 0.7383 - val_loss: 0.5451\n",
                        "Epoch 30/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7405 - loss: 0.5263 - val_accuracy: 0.7376 - val_loss: 0.5455\n",
                        "Epoch 31/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7418 - loss: 0.5320 - val_accuracy: 0.7391 - val_loss: 0.5442\n",
                        "Epoch 32/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7312 - loss: 0.5430 - val_accuracy: 0.7371 - val_loss: 0.5446\n",
                        "Epoch 33/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7403 - loss: 0.5304 - val_accuracy: 0.7352 - val_loss: 0.5458\n",
                        "Epoch 34/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7397 - loss: 0.5323 - val_accuracy: 0.7367 - val_loss: 0.5450\n",
                        "Epoch 35/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7427 - loss: 0.5300 - val_accuracy: 0.7360 - val_loss: 0.5464\n",
                        "Epoch 36/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7386 - loss: 0.5342 - val_accuracy: 0.7363 - val_loss: 0.5448\n",
                        "Epoch 37/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7414 - loss: 0.5299 - val_accuracy: 0.7389 - val_loss: 0.5459\n",
                        "Epoch 38/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7363 - loss: 0.5384 - val_accuracy: 0.7387 - val_loss: 0.5458\n",
                        "Epoch 39/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7341 - loss: 0.5413 - val_accuracy: 0.7380 - val_loss: 0.5457\n",
                        "Epoch 40/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7401 - loss: 0.5304 - val_accuracy: 0.7369 - val_loss: 0.5449\n",
                        "Epoch 41/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7349 - loss: 0.5367 - val_accuracy: 0.7392 - val_loss: 0.5461\n",
                        "Epoch 42/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7357 - loss: 0.5380 - val_accuracy: 0.7371 - val_loss: 0.5467\n",
                        "Epoch 43/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7372 - loss: 0.5351 - val_accuracy: 0.7387 - val_loss: 0.5455\n",
                        "Epoch 44/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7425 - loss: 0.5312 - val_accuracy: 0.7372 - val_loss: 0.5471\n",
                        "Epoch 45/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7313 - loss: 0.5394 - val_accuracy: 0.7387 - val_loss: 0.5464\n",
                        "Epoch 46/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7429 - loss: 0.5297 - val_accuracy: 0.7383 - val_loss: 0.5459\n",
                        "Epoch 47/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7415 - loss: 0.5327 - val_accuracy: 0.7396 - val_loss: 0.5468\n",
                        "Epoch 48/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7396 - loss: 0.5322 - val_accuracy: 0.7387 - val_loss: 0.5460\n",
                        "Epoch 49/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7387 - loss: 0.5304 - val_accuracy: 0.7362 - val_loss: 0.5478\n",
                        "Epoch 50/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7328 - loss: 0.5380 - val_accuracy: 0.7383 - val_loss: 0.5465\n",
                        "Epoch 51/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7400 - loss: 0.5361 - val_accuracy: 0.7385 - val_loss: 0.5459\n",
                        "Epoch 52/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7404 - loss: 0.5318 - val_accuracy: 0.7374 - val_loss: 0.5466\n",
                        "Epoch 53/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7363 - loss: 0.5343 - val_accuracy: 0.7389 - val_loss: 0.5476\n",
                        "Epoch 54/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7373 - loss: 0.5360 - val_accuracy: 0.7378 - val_loss: 0.5471\n",
                        "Epoch 55/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7412 - loss: 0.5304 - val_accuracy: 0.7378 - val_loss: 0.5497\n",
                        "Epoch 56/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7339 - loss: 0.5363 - val_accuracy: 0.7387 - val_loss: 0.5471\n",
                        "Epoch 57/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7420 - loss: 0.5292 - val_accuracy: 0.7383 - val_loss: 0.5495\n",
                        "Epoch 58/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7401 - loss: 0.5330 - val_accuracy: 0.7392 - val_loss: 0.5469\n",
                        "Epoch 59/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7417 - loss: 0.5298 - val_accuracy: 0.7389 - val_loss: 0.5473\n",
                        "Epoch 60/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.7335 - loss: 0.5383 - val_accuracy: 0.7382 - val_loss: 0.5474\n",
                        "Epoch 61/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7373 - loss: 0.5349 - val_accuracy: 0.7392 - val_loss: 0.5477\n",
                        "Epoch 62/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7361 - loss: 0.5331 - val_accuracy: 0.7385 - val_loss: 0.5479\n",
                        "Epoch 63/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7403 - loss: 0.5325 - val_accuracy: 0.7398 - val_loss: 0.5480\n",
                        "Epoch 64/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7364 - loss: 0.5318 - val_accuracy: 0.7389 - val_loss: 0.5478\n",
                        "Epoch 65/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7390 - loss: 0.5368 - val_accuracy: 0.7389 - val_loss: 0.5482\n",
                        "Epoch 66/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7464 - loss: 0.5246 - val_accuracy: 0.7389 - val_loss: 0.5479\n",
                        "Epoch 67/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7417 - loss: 0.5320 - val_accuracy: 0.7391 - val_loss: 0.5498\n",
                        "Epoch 68/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7380 - loss: 0.5299 - val_accuracy: 0.7385 - val_loss: 0.5490\n",
                        "Epoch 69/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7372 - loss: 0.5327 - val_accuracy: 0.7385 - val_loss: 0.5479\n",
                        "Epoch 70/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7395 - loss: 0.5319 - val_accuracy: 0.7380 - val_loss: 0.5492\n",
                        "Epoch 71/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7372 - loss: 0.5335 - val_accuracy: 0.7394 - val_loss: 0.5490\n",
                        "Epoch 72/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7368 - loss: 0.5358 - val_accuracy: 0.7385 - val_loss: 0.5489\n",
                        "Epoch 73/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7407 - loss: 0.5320 - val_accuracy: 0.7396 - val_loss: 0.5487\n",
                        "Epoch 74/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7402 - loss: 0.5315 - val_accuracy: 0.7389 - val_loss: 0.5489\n",
                        "Epoch 75/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7403 - loss: 0.5320 - val_accuracy: 0.7372 - val_loss: 0.5498\n",
                        "Epoch 76/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7435 - loss: 0.5288 - val_accuracy: 0.7389 - val_loss: 0.5493\n",
                        "Epoch 77/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7404 - loss: 0.5286 - val_accuracy: 0.7391 - val_loss: 0.5498\n",
                        "Epoch 78/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7352 - loss: 0.5352 - val_accuracy: 0.7391 - val_loss: 0.5500\n",
                        "Epoch 79/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7460 - loss: 0.5240 - val_accuracy: 0.7389 - val_loss: 0.5504\n",
                        "Epoch 80/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7458 - loss: 0.5269 - val_accuracy: 0.7387 - val_loss: 0.5492\n",
                        "Epoch 81/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7432 - loss: 0.5277 - val_accuracy: 0.7376 - val_loss: 0.5496\n",
                        "Epoch 82/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7393 - loss: 0.5331 - val_accuracy: 0.7382 - val_loss: 0.5499\n",
                        "Epoch 83/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7394 - loss: 0.5294 - val_accuracy: 0.7387 - val_loss: 0.5493\n",
                        "Epoch 84/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7422 - loss: 0.5314 - val_accuracy: 0.7400 - val_loss: 0.5490\n",
                        "Epoch 85/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7342 - loss: 0.5377 - val_accuracy: 0.7380 - val_loss: 0.5496\n",
                        "Epoch 86/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7381 - loss: 0.5302 - val_accuracy: 0.7376 - val_loss: 0.5505\n",
                        "Epoch 87/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7338 - loss: 0.5383 - val_accuracy: 0.7392 - val_loss: 0.5501\n",
                        "Epoch 88/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7367 - loss: 0.5333 - val_accuracy: 0.7387 - val_loss: 0.5499\n",
                        "Epoch 89/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7380 - loss: 0.5307 - val_accuracy: 0.7383 - val_loss: 0.5491\n",
                        "Epoch 90/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7400 - loss: 0.5341 - val_accuracy: 0.7374 - val_loss: 0.5498\n",
                        "Epoch 91/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7424 - loss: 0.5306 - val_accuracy: 0.7389 - val_loss: 0.5512\n",
                        "Epoch 92/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7409 - loss: 0.5298 - val_accuracy: 0.7383 - val_loss: 0.5501\n",
                        "Epoch 93/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - accuracy: 0.7391 - loss: 0.5300 - val_accuracy: 0.7387 - val_loss: 0.5497\n",
                        "Epoch 94/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7357 - loss: 0.5342 - val_accuracy: 0.7389 - val_loss: 0.5501\n",
                        "Epoch 95/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7358 - loss: 0.5318 - val_accuracy: 0.7385 - val_loss: 0.5494\n",
                        "Epoch 96/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7466 - loss: 0.5251 - val_accuracy: 0.7383 - val_loss: 0.5502\n",
                        "Epoch 97/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7391 - loss: 0.5335 - val_accuracy: 0.7345 - val_loss: 0.5500\n",
                        "Epoch 98/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7417 - loss: 0.5291 - val_accuracy: 0.7371 - val_loss: 0.5522\n",
                        "Epoch 99/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7420 - loss: 0.5291 - val_accuracy: 0.7387 - val_loss: 0.5498\n",
                        "Epoch 100/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7370 - loss: 0.5286 - val_accuracy: 0.7382 - val_loss: 0.5500\n",
                        "Epoch 101/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7417 - loss: 0.5281 - val_accuracy: 0.7385 - val_loss: 0.5515\n",
                        "Epoch 102/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7437 - loss: 0.5295 - val_accuracy: 0.7341 - val_loss: 0.5527\n",
                        "Epoch 103/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7400 - loss: 0.5312 - val_accuracy: 0.7382 - val_loss: 0.5502\n",
                        "Epoch 104/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7379 - loss: 0.5323 - val_accuracy: 0.7385 - val_loss: 0.5525\n",
                        "Epoch 105/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7425 - loss: 0.5312 - val_accuracy: 0.7376 - val_loss: 0.5522\n",
                        "Epoch 106/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7406 - loss: 0.5299 - val_accuracy: 0.7382 - val_loss: 0.5506\n",
                        "Epoch 107/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7359 - loss: 0.5349 - val_accuracy: 0.7383 - val_loss: 0.5509\n",
                        "Epoch 108/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7431 - loss: 0.5301 - val_accuracy: 0.7387 - val_loss: 0.5515\n",
                        "Epoch 109/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7383 - loss: 0.5286 - val_accuracy: 0.7385 - val_loss: 0.5501\n",
                        "Epoch 110/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7409 - loss: 0.5309 - val_accuracy: 0.7383 - val_loss: 0.5506\n",
                        "Epoch 111/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7413 - loss: 0.5294 - val_accuracy: 0.7394 - val_loss: 0.5508\n",
                        "Epoch 112/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7382 - loss: 0.5344 - val_accuracy: 0.7383 - val_loss: 0.5503\n",
                        "Epoch 113/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - accuracy: 0.7414 - loss: 0.5300 - val_accuracy: 0.7378 - val_loss: 0.5514\n",
                        "Epoch 114/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7410 - loss: 0.5308 - val_accuracy: 0.7387 - val_loss: 0.5515\n",
                        "Epoch 115/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7455 - loss: 0.5262 - val_accuracy: 0.7374 - val_loss: 0.5511\n",
                        "Epoch 116/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7420 - loss: 0.5327 - val_accuracy: 0.7389 - val_loss: 0.5517\n",
                        "Epoch 117/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7408 - loss: 0.5295 - val_accuracy: 0.7394 - val_loss: 0.5511\n",
                        "Epoch 118/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7371 - loss: 0.5301 - val_accuracy: 0.7389 - val_loss: 0.5509\n",
                        "Epoch 119/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.7436 - loss: 0.5258 - val_accuracy: 0.7378 - val_loss: 0.5525\n",
                        "Epoch 120/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7452 - loss: 0.5270 - val_accuracy: 0.7387 - val_loss: 0.5519\n",
                        "Epoch 121/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7384 - loss: 0.5308 - val_accuracy: 0.7382 - val_loss: 0.5511\n",
                        "Epoch 122/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7403 - loss: 0.5293 - val_accuracy: 0.7396 - val_loss: 0.5511\n",
                        "Epoch 123/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7458 - loss: 0.5235 - val_accuracy: 0.7391 - val_loss: 0.5518\n",
                        "Epoch 124/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7421 - loss: 0.5316 - val_accuracy: 0.7380 - val_loss: 0.5522\n",
                        "Epoch 125/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7411 - loss: 0.5287 - val_accuracy: 0.7389 - val_loss: 0.5520\n",
                        "Epoch 126/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7417 - loss: 0.5251 - val_accuracy: 0.7385 - val_loss: 0.5532\n",
                        "Epoch 127/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.7393 - loss: 0.5330 - val_accuracy: 0.7391 - val_loss: 0.5524\n",
                        "Epoch 128/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7411 - loss: 0.5280 - val_accuracy: 0.7380 - val_loss: 0.5545\n",
                        "Epoch 129/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7393 - loss: 0.5304 - val_accuracy: 0.7378 - val_loss: 0.5537\n",
                        "Epoch 130/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.7388 - loss: 0.5264 - val_accuracy: 0.7398 - val_loss: 0.5524\n",
                        "Epoch 131/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7482 - loss: 0.5234 - val_accuracy: 0.7378 - val_loss: 0.5536\n",
                        "Epoch 132/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.7412 - loss: 0.5306 - val_accuracy: 0.7389 - val_loss: 0.5548\n",
                        "Epoch 133/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7374 - loss: 0.5318 - val_accuracy: 0.7372 - val_loss: 0.5538\n",
                        "Epoch 134/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.7358 - loss: 0.5321 - val_accuracy: 0.7374 - val_loss: 0.5534\n",
                        "Epoch 135/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7428 - loss: 0.5244 - val_accuracy: 0.7369 - val_loss: 0.5525\n",
                        "Epoch 136/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7389 - loss: 0.5309 - val_accuracy: 0.7365 - val_loss: 0.5545\n",
                        "Epoch 137/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7380 - loss: 0.5314 - val_accuracy: 0.7383 - val_loss: 0.5521\n",
                        "Epoch 138/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7419 - loss: 0.5291 - val_accuracy: 0.7374 - val_loss: 0.5532\n",
                        "Epoch 139/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7406 - loss: 0.5294 - val_accuracy: 0.7387 - val_loss: 0.5531\n",
                        "Epoch 140/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7425 - loss: 0.5262 - val_accuracy: 0.7387 - val_loss: 0.5525\n",
                        "Epoch 141/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7409 - loss: 0.5293 - val_accuracy: 0.7391 - val_loss: 0.5526\n",
                        "Epoch 142/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7448 - loss: 0.5270 - val_accuracy: 0.7389 - val_loss: 0.5529\n",
                        "Epoch 143/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7445 - loss: 0.5250 - val_accuracy: 0.7374 - val_loss: 0.5542\n",
                        "Epoch 144/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7393 - loss: 0.5278 - val_accuracy: 0.7380 - val_loss: 0.5538\n",
                        "Epoch 145/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7386 - loss: 0.5309 - val_accuracy: 0.7383 - val_loss: 0.5535\n",
                        "Epoch 146/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7437 - loss: 0.5262 - val_accuracy: 0.7380 - val_loss: 0.5538\n",
                        "Epoch 147/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7336 - loss: 0.5352 - val_accuracy: 0.7385 - val_loss: 0.5542\n",
                        "Epoch 148/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7397 - loss: 0.5295 - val_accuracy: 0.7372 - val_loss: 0.5542\n",
                        "Epoch 149/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7430 - loss: 0.5220 - val_accuracy: 0.7382 - val_loss: 0.5534\n",
                        "Epoch 150/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7355 - loss: 0.5319 - val_accuracy: 0.7378 - val_loss: 0.5540\n",
                        "Epoch 151/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7453 - loss: 0.5241 - val_accuracy: 0.7383 - val_loss: 0.5521\n",
                        "Epoch 152/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7404 - loss: 0.5266 - val_accuracy: 0.7380 - val_loss: 0.5532\n",
                        "Epoch 153/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7456 - loss: 0.5228 - val_accuracy: 0.7374 - val_loss: 0.5542\n",
                        "Epoch 154/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7408 - loss: 0.5316 - val_accuracy: 0.7378 - val_loss: 0.5555\n",
                        "Epoch 155/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7404 - loss: 0.5285 - val_accuracy: 0.7382 - val_loss: 0.5540\n",
                        "Epoch 156/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7441 - loss: 0.5282 - val_accuracy: 0.7387 - val_loss: 0.5537\n",
                        "Epoch 157/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7455 - loss: 0.5256 - val_accuracy: 0.7356 - val_loss: 0.5552\n",
                        "Epoch 158/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7392 - loss: 0.5313 - val_accuracy: 0.7383 - val_loss: 0.5542\n",
                        "Epoch 159/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7436 - loss: 0.5291 - val_accuracy: 0.7382 - val_loss: 0.5539\n",
                        "Epoch 160/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.7377 - loss: 0.5314 - val_accuracy: 0.7372 - val_loss: 0.5550\n",
                        "Epoch 161/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7379 - loss: 0.5312 - val_accuracy: 0.7385 - val_loss: 0.5532\n",
                        "Epoch 162/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7442 - loss: 0.5253 - val_accuracy: 0.7389 - val_loss: 0.5539\n",
                        "Epoch 163/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7463 - loss: 0.5220 - val_accuracy: 0.7378 - val_loss: 0.5551\n",
                        "Epoch 164/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7354 - loss: 0.5323 - val_accuracy: 0.7389 - val_loss: 0.5530\n",
                        "Epoch 165/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7423 - loss: 0.5257 - val_accuracy: 0.7389 - val_loss: 0.5527\n",
                        "Epoch 166/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.7405 - loss: 0.5303 - val_accuracy: 0.7382 - val_loss: 0.5545\n",
                        "Epoch 167/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7415 - loss: 0.5284 - val_accuracy: 0.7374 - val_loss: 0.5550\n",
                        "Epoch 168/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7388 - loss: 0.5291 - val_accuracy: 0.7374 - val_loss: 0.5545\n",
                        "Epoch 169/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7334 - loss: 0.5328 - val_accuracy: 0.7380 - val_loss: 0.5549\n",
                        "Epoch 170/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.7460 - loss: 0.5227 - val_accuracy: 0.7385 - val_loss: 0.5548\n",
                        "Epoch 171/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7438 - loss: 0.5253 - val_accuracy: 0.7389 - val_loss: 0.5541\n",
                        "Epoch 172/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7414 - loss: 0.5279 - val_accuracy: 0.7378 - val_loss: 0.5548\n",
                        "Epoch 173/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7444 - loss: 0.5223 - val_accuracy: 0.7376 - val_loss: 0.5551\n",
                        "Epoch 174/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7418 - loss: 0.5287 - val_accuracy: 0.7387 - val_loss: 0.5549\n",
                        "Epoch 175/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7385 - loss: 0.5320 - val_accuracy: 0.7374 - val_loss: 0.5558\n",
                        "Epoch 176/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7355 - loss: 0.5330 - val_accuracy: 0.7392 - val_loss: 0.5546\n",
                        "Epoch 177/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7389 - loss: 0.5316 - val_accuracy: 0.7385 - val_loss: 0.5543\n",
                        "Epoch 178/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7422 - loss: 0.5267 - val_accuracy: 0.7387 - val_loss: 0.5550\n",
                        "Epoch 179/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7429 - loss: 0.5277 - val_accuracy: 0.7387 - val_loss: 0.5561\n",
                        "Epoch 180/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.7368 - loss: 0.5347 - val_accuracy: 0.7385 - val_loss: 0.5561\n",
                        "Epoch 181/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7364 - loss: 0.5328 - val_accuracy: 0.7382 - val_loss: 0.5556\n",
                        "Epoch 182/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7411 - loss: 0.5300 - val_accuracy: 0.7387 - val_loss: 0.5555\n",
                        "Epoch 183/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7419 - loss: 0.5283 - val_accuracy: 0.7376 - val_loss: 0.5563\n",
                        "Epoch 184/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7444 - loss: 0.5248 - val_accuracy: 0.7369 - val_loss: 0.5554\n",
                        "Epoch 185/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7402 - loss: 0.5261 - val_accuracy: 0.7378 - val_loss: 0.5546\n",
                        "Epoch 186/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7408 - loss: 0.5273 - val_accuracy: 0.7345 - val_loss: 0.5573\n",
                        "Epoch 187/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7427 - loss: 0.5251 - val_accuracy: 0.7378 - val_loss: 0.5554\n",
                        "Epoch 188/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7429 - loss: 0.5267 - val_accuracy: 0.7363 - val_loss: 0.5579\n",
                        "Epoch 189/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7382 - loss: 0.5320 - val_accuracy: 0.7380 - val_loss: 0.5560\n",
                        "Epoch 190/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7355 - loss: 0.5322 - val_accuracy: 0.7367 - val_loss: 0.5561\n",
                        "Epoch 191/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7435 - loss: 0.5267 - val_accuracy: 0.7376 - val_loss: 0.5549\n",
                        "Epoch 192/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7443 - loss: 0.5296 - val_accuracy: 0.7391 - val_loss: 0.5551\n",
                        "Epoch 193/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7410 - loss: 0.5295 - val_accuracy: 0.7371 - val_loss: 0.5574\n",
                        "Epoch 194/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7388 - loss: 0.5289 - val_accuracy: 0.7389 - val_loss: 0.5561\n",
                        "Epoch 195/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7376 - loss: 0.5317 - val_accuracy: 0.7382 - val_loss: 0.5562\n",
                        "Epoch 196/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.7393 - loss: 0.5308 - val_accuracy: 0.7372 - val_loss: 0.5564\n",
                        "Epoch 197/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7447 - loss: 0.5278 - val_accuracy: 0.7332 - val_loss: 0.5571\n",
                        "Epoch 198/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7396 - loss: 0.5300 - val_accuracy: 0.7372 - val_loss: 0.5560\n",
                        "Epoch 199/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7393 - loss: 0.5292 - val_accuracy: 0.7380 - val_loss: 0.5562\n",
                        "Epoch 200/200\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7431 - loss: 0.5232 - val_accuracy: 0.7358 - val_loss: 0.5558\n",
                        "215/215 - 0s - 257us/step - accuracy: 0.7222 - loss: 0.5747\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized Loss 2: 0.5746605396270752, Optimized Accuracy 2: 0.7221574187278748\n"
                    ]
                }
            ],
            "source": [
                "# Model Optimization - Attempt 2: Change Activation Functions and Increase Epochs\n",
                "nn_opt_2 = tf.keras.models.Sequential()\n",
                "\n",
                "# Add more neurons and change the activation functions\n",
                "nn_opt_2.add(tf.keras.layers.Dense(units=100, input_dim=X_train_scaled.shape[1], activation='tanh'))\n",
                "nn_opt_2.add(tf.keras.layers.Dense(units=50, activation='tanh'))\n",
                "nn_opt_2.add(tf.keras.layers.Dense(units=25, activation='tanh'))\n",
                "nn_opt_2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
                "\n",
                "# Compile the optimized model\n",
                "nn_opt_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Train the optimized model with more epochs\n",
                "history_opt_2 = nn_opt_2.fit(X_train_scaled, y_train, epochs=200, batch_size=32, validation_split=0.2)\n",
                "\n",
                "# Evaluate the optimized model\n",
                "model_loss_opt_2, model_accuracy_opt_2 = nn_opt_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
                "print(f\"Optimized Loss 2: {model_loss_opt_2}, Optimized Accuracy 2: {model_accuracy_opt_2}\")\n",
                "\n",
                "# Save the optimized model\n",
                "nn_opt_2.save('AlphabetSoupCharity_Optimization_2.h5')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c1c3fd3",
            "metadata": {},
            "source": [
                "Optimize Model #3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "id": "582bc067",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.6727 - loss: 0.6200 - val_accuracy: 0.7341 - val_loss: 0.5560\n",
                        "Epoch 2/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7161 - loss: 0.5791 - val_accuracy: 0.7385 - val_loss: 0.5527\n",
                        "Epoch 3/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7236 - loss: 0.5626 - val_accuracy: 0.7385 - val_loss: 0.5514\n",
                        "Epoch 4/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7246 - loss: 0.5629 - val_accuracy: 0.7372 - val_loss: 0.5454\n",
                        "Epoch 5/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7273 - loss: 0.5590 - val_accuracy: 0.7389 - val_loss: 0.5459\n",
                        "Epoch 6/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7315 - loss: 0.5568 - val_accuracy: 0.7358 - val_loss: 0.5484\n",
                        "Epoch 7/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7339 - loss: 0.5521 - val_accuracy: 0.7383 - val_loss: 0.5479\n",
                        "Epoch 8/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7293 - loss: 0.5528 - val_accuracy: 0.7374 - val_loss: 0.5471\n",
                        "Epoch 9/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7298 - loss: 0.5545 - val_accuracy: 0.7394 - val_loss: 0.5467\n",
                        "Epoch 10/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7296 - loss: 0.5540 - val_accuracy: 0.7403 - val_loss: 0.5493\n",
                        "Epoch 11/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7342 - loss: 0.5532 - val_accuracy: 0.7367 - val_loss: 0.5457\n",
                        "Epoch 12/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7300 - loss: 0.5534 - val_accuracy: 0.7369 - val_loss: 0.5461\n",
                        "Epoch 13/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7357 - loss: 0.5503 - val_accuracy: 0.7385 - val_loss: 0.5455\n",
                        "Epoch 14/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7242 - loss: 0.5606 - val_accuracy: 0.7391 - val_loss: 0.5451\n",
                        "Epoch 15/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7343 - loss: 0.5541 - val_accuracy: 0.7372 - val_loss: 0.5452\n",
                        "Epoch 16/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7336 - loss: 0.5531 - val_accuracy: 0.7372 - val_loss: 0.5477\n",
                        "Epoch 17/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7313 - loss: 0.5534 - val_accuracy: 0.7391 - val_loss: 0.5451\n",
                        "Epoch 18/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7311 - loss: 0.5528 - val_accuracy: 0.7402 - val_loss: 0.5435\n",
                        "Epoch 19/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7323 - loss: 0.5512 - val_accuracy: 0.7392 - val_loss: 0.5458\n",
                        "Epoch 20/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7325 - loss: 0.5482 - val_accuracy: 0.7407 - val_loss: 0.5447\n",
                        "Epoch 21/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7288 - loss: 0.5519 - val_accuracy: 0.7391 - val_loss: 0.5427\n",
                        "Epoch 22/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.7328 - loss: 0.5508 - val_accuracy: 0.7383 - val_loss: 0.5457\n",
                        "Epoch 23/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7377 - loss: 0.5468 - val_accuracy: 0.7391 - val_loss: 0.5452\n",
                        "Epoch 24/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7353 - loss: 0.5480 - val_accuracy: 0.7380 - val_loss: 0.5433\n",
                        "Epoch 25/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7299 - loss: 0.5497 - val_accuracy: 0.7385 - val_loss: 0.5443\n",
                        "Epoch 26/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7338 - loss: 0.5479 - val_accuracy: 0.7409 - val_loss: 0.5461\n",
                        "Epoch 27/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7371 - loss: 0.5461 - val_accuracy: 0.7394 - val_loss: 0.5423\n",
                        "Epoch 28/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7345 - loss: 0.5480 - val_accuracy: 0.7363 - val_loss: 0.5447\n",
                        "Epoch 29/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7286 - loss: 0.5520 - val_accuracy: 0.7394 - val_loss: 0.5454\n",
                        "Epoch 30/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7335 - loss: 0.5490 - val_accuracy: 0.7396 - val_loss: 0.5433\n",
                        "Epoch 31/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7322 - loss: 0.5470 - val_accuracy: 0.7411 - val_loss: 0.5444\n",
                        "Epoch 32/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7362 - loss: 0.5458 - val_accuracy: 0.7411 - val_loss: 0.5460\n",
                        "Epoch 33/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7309 - loss: 0.5514 - val_accuracy: 0.7405 - val_loss: 0.5447\n",
                        "Epoch 34/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7260 - loss: 0.5548 - val_accuracy: 0.7411 - val_loss: 0.5424\n",
                        "Epoch 35/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7279 - loss: 0.5509 - val_accuracy: 0.7411 - val_loss: 0.5429\n",
                        "Epoch 36/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7376 - loss: 0.5415 - val_accuracy: 0.7409 - val_loss: 0.5437\n",
                        "Epoch 37/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7320 - loss: 0.5494 - val_accuracy: 0.7411 - val_loss: 0.5443\n",
                        "Epoch 38/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7345 - loss: 0.5462 - val_accuracy: 0.7400 - val_loss: 0.5418\n",
                        "Epoch 39/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7277 - loss: 0.5528 - val_accuracy: 0.7400 - val_loss: 0.5422\n",
                        "Epoch 40/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7278 - loss: 0.5515 - val_accuracy: 0.7374 - val_loss: 0.5424\n",
                        "Epoch 41/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7326 - loss: 0.5466 - val_accuracy: 0.7392 - val_loss: 0.5423\n",
                        "Epoch 42/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7376 - loss: 0.5446 - val_accuracy: 0.7409 - val_loss: 0.5426\n",
                        "Epoch 43/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7356 - loss: 0.5467 - val_accuracy: 0.7409 - val_loss: 0.5435\n",
                        "Epoch 44/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7324 - loss: 0.5481 - val_accuracy: 0.7398 - val_loss: 0.5432\n",
                        "Epoch 45/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7296 - loss: 0.5498 - val_accuracy: 0.7407 - val_loss: 0.5418\n",
                        "Epoch 46/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7363 - loss: 0.5402 - val_accuracy: 0.7394 - val_loss: 0.5436\n",
                        "Epoch 47/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.7335 - loss: 0.5465 - val_accuracy: 0.7394 - val_loss: 0.5453\n",
                        "Epoch 48/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7306 - loss: 0.5480 - val_accuracy: 0.7394 - val_loss: 0.5437\n",
                        "Epoch 49/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7304 - loss: 0.5474 - val_accuracy: 0.7407 - val_loss: 0.5432\n",
                        "Epoch 50/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7328 - loss: 0.5414 - val_accuracy: 0.7398 - val_loss: 0.5421\n",
                        "Epoch 51/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7315 - loss: 0.5482 - val_accuracy: 0.7405 - val_loss: 0.5434\n",
                        "Epoch 52/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7366 - loss: 0.5428 - val_accuracy: 0.7387 - val_loss: 0.5433\n",
                        "Epoch 53/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7331 - loss: 0.5453 - val_accuracy: 0.7403 - val_loss: 0.5432\n",
                        "Epoch 54/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7306 - loss: 0.5504 - val_accuracy: 0.7400 - val_loss: 0.5421\n",
                        "Epoch 55/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7299 - loss: 0.5493 - val_accuracy: 0.7387 - val_loss: 0.5425\n",
                        "Epoch 56/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7372 - loss: 0.5418 - val_accuracy: 0.7387 - val_loss: 0.5432\n",
                        "Epoch 57/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7272 - loss: 0.5520 - val_accuracy: 0.7382 - val_loss: 0.5434\n",
                        "Epoch 58/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7320 - loss: 0.5468 - val_accuracy: 0.7385 - val_loss: 0.5432\n",
                        "Epoch 59/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7319 - loss: 0.5450 - val_accuracy: 0.7378 - val_loss: 0.5443\n",
                        "Epoch 60/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7396 - loss: 0.5406 - val_accuracy: 0.7403 - val_loss: 0.5443\n",
                        "Epoch 61/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7341 - loss: 0.5479 - val_accuracy: 0.7389 - val_loss: 0.5434\n",
                        "Epoch 62/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7313 - loss: 0.5486 - val_accuracy: 0.7402 - val_loss: 0.5427\n",
                        "Epoch 63/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7357 - loss: 0.5446 - val_accuracy: 0.7392 - val_loss: 0.5433\n",
                        "Epoch 64/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7317 - loss: 0.5449 - val_accuracy: 0.7385 - val_loss: 0.5447\n",
                        "Epoch 65/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7421 - loss: 0.5362 - val_accuracy: 0.7387 - val_loss: 0.5457\n",
                        "Epoch 66/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7365 - loss: 0.5445 - val_accuracy: 0.7398 - val_loss: 0.5429\n",
                        "Epoch 67/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7294 - loss: 0.5474 - val_accuracy: 0.7389 - val_loss: 0.5427\n",
                        "Epoch 68/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7344 - loss: 0.5422 - val_accuracy: 0.7380 - val_loss: 0.5424\n",
                        "Epoch 69/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7409 - loss: 0.5363 - val_accuracy: 0.7396 - val_loss: 0.5464\n",
                        "Epoch 70/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7344 - loss: 0.5411 - val_accuracy: 0.7394 - val_loss: 0.5435\n",
                        "Epoch 71/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7304 - loss: 0.5493 - val_accuracy: 0.7416 - val_loss: 0.5441\n",
                        "Epoch 72/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7360 - loss: 0.5450 - val_accuracy: 0.7398 - val_loss: 0.5438\n",
                        "Epoch 73/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7334 - loss: 0.5457 - val_accuracy: 0.7387 - val_loss: 0.5433\n",
                        "Epoch 74/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7299 - loss: 0.5443 - val_accuracy: 0.7389 - val_loss: 0.5445\n",
                        "Epoch 75/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7337 - loss: 0.5444 - val_accuracy: 0.7392 - val_loss: 0.5446\n",
                        "Epoch 76/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7357 - loss: 0.5438 - val_accuracy: 0.7380 - val_loss: 0.5441\n",
                        "Epoch 77/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7352 - loss: 0.5410 - val_accuracy: 0.7385 - val_loss: 0.5433\n",
                        "Epoch 78/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7339 - loss: 0.5473 - val_accuracy: 0.7382 - val_loss: 0.5440\n",
                        "Epoch 79/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7323 - loss: 0.5428 - val_accuracy: 0.7362 - val_loss: 0.5437\n",
                        "Epoch 80/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7290 - loss: 0.5490 - val_accuracy: 0.7391 - val_loss: 0.5449\n",
                        "Epoch 81/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7347 - loss: 0.5453 - val_accuracy: 0.7405 - val_loss: 0.5446\n",
                        "Epoch 82/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7307 - loss: 0.5491 - val_accuracy: 0.7380 - val_loss: 0.5441\n",
                        "Epoch 83/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7348 - loss: 0.5438 - val_accuracy: 0.7391 - val_loss: 0.5437\n",
                        "Epoch 84/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7320 - loss: 0.5457 - val_accuracy: 0.7385 - val_loss: 0.5436\n",
                        "Epoch 85/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7279 - loss: 0.5521 - val_accuracy: 0.7403 - val_loss: 0.5456\n",
                        "Epoch 86/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7339 - loss: 0.5407 - val_accuracy: 0.7403 - val_loss: 0.5446\n",
                        "Epoch 87/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7385 - loss: 0.5380 - val_accuracy: 0.7400 - val_loss: 0.5452\n",
                        "Epoch 88/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7322 - loss: 0.5463 - val_accuracy: 0.7407 - val_loss: 0.5437\n",
                        "Epoch 89/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7373 - loss: 0.5422 - val_accuracy: 0.7402 - val_loss: 0.5465\n",
                        "Epoch 90/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7374 - loss: 0.5410 - val_accuracy: 0.7378 - val_loss: 0.5443\n",
                        "Epoch 91/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7358 - loss: 0.5433 - val_accuracy: 0.7387 - val_loss: 0.5460\n",
                        "Epoch 92/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7370 - loss: 0.5431 - val_accuracy: 0.7392 - val_loss: 0.5439\n",
                        "Epoch 93/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7368 - loss: 0.5406 - val_accuracy: 0.7391 - val_loss: 0.5437\n",
                        "Epoch 94/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7306 - loss: 0.5474 - val_accuracy: 0.7382 - val_loss: 0.5446\n",
                        "Epoch 95/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7354 - loss: 0.5462 - val_accuracy: 0.7385 - val_loss: 0.5434\n",
                        "Epoch 96/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7316 - loss: 0.5424 - val_accuracy: 0.7398 - val_loss: 0.5456\n",
                        "Epoch 97/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7356 - loss: 0.5455 - val_accuracy: 0.7405 - val_loss: 0.5437\n",
                        "Epoch 98/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7395 - loss: 0.5385 - val_accuracy: 0.7400 - val_loss: 0.5453\n",
                        "Epoch 99/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7364 - loss: 0.5452 - val_accuracy: 0.7398 - val_loss: 0.5451\n",
                        "Epoch 100/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7334 - loss: 0.5445 - val_accuracy: 0.7398 - val_loss: 0.5434\n",
                        "Epoch 101/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7358 - loss: 0.5436 - val_accuracy: 0.7398 - val_loss: 0.5442\n",
                        "Epoch 102/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7335 - loss: 0.5432 - val_accuracy: 0.7398 - val_loss: 0.5441\n",
                        "Epoch 103/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7289 - loss: 0.5465 - val_accuracy: 0.7398 - val_loss: 0.5458\n",
                        "Epoch 104/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7353 - loss: 0.5426 - val_accuracy: 0.7387 - val_loss: 0.5460\n",
                        "Epoch 105/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7337 - loss: 0.5406 - val_accuracy: 0.7374 - val_loss: 0.5452\n",
                        "Epoch 106/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7331 - loss: 0.5430 - val_accuracy: 0.7394 - val_loss: 0.5475\n",
                        "Epoch 107/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7379 - loss: 0.5436 - val_accuracy: 0.7389 - val_loss: 0.5447\n",
                        "Epoch 108/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7364 - loss: 0.5409 - val_accuracy: 0.7387 - val_loss: 0.5448\n",
                        "Epoch 109/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7356 - loss: 0.5409 - val_accuracy: 0.7385 - val_loss: 0.5451\n",
                        "Epoch 110/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7369 - loss: 0.5430 - val_accuracy: 0.7387 - val_loss: 0.5444\n",
                        "Epoch 111/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7327 - loss: 0.5442 - val_accuracy: 0.7383 - val_loss: 0.5446\n",
                        "Epoch 112/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7377 - loss: 0.5404 - val_accuracy: 0.7392 - val_loss: 0.5457\n",
                        "Epoch 113/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7347 - loss: 0.5485 - val_accuracy: 0.7391 - val_loss: 0.5459\n",
                        "Epoch 114/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7396 - loss: 0.5358 - val_accuracy: 0.7407 - val_loss: 0.5458\n",
                        "Epoch 115/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7362 - loss: 0.5437 - val_accuracy: 0.7411 - val_loss: 0.5455\n",
                        "Epoch 116/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7340 - loss: 0.5454 - val_accuracy: 0.7391 - val_loss: 0.5482\n",
                        "Epoch 117/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7356 - loss: 0.5412 - val_accuracy: 0.7383 - val_loss: 0.5450\n",
                        "Epoch 118/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.7350 - loss: 0.5422 - val_accuracy: 0.7376 - val_loss: 0.5467\n",
                        "Epoch 119/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7354 - loss: 0.5427 - val_accuracy: 0.7383 - val_loss: 0.5459\n",
                        "Epoch 120/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7407 - loss: 0.5354 - val_accuracy: 0.7389 - val_loss: 0.5462\n",
                        "Epoch 121/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7363 - loss: 0.5409 - val_accuracy: 0.7402 - val_loss: 0.5462\n",
                        "Epoch 122/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.7367 - loss: 0.5409 - val_accuracy: 0.7371 - val_loss: 0.5461\n",
                        "Epoch 123/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7387 - loss: 0.5410 - val_accuracy: 0.7403 - val_loss: 0.5462\n",
                        "Epoch 124/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7334 - loss: 0.5450 - val_accuracy: 0.7396 - val_loss: 0.5467\n",
                        "Epoch 125/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.7373 - loss: 0.5399 - val_accuracy: 0.7400 - val_loss: 0.5444\n",
                        "Epoch 126/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7305 - loss: 0.5450 - val_accuracy: 0.7392 - val_loss: 0.5453\n",
                        "Epoch 127/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7323 - loss: 0.5393 - val_accuracy: 0.7407 - val_loss: 0.5454\n",
                        "Epoch 128/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7401 - loss: 0.5410 - val_accuracy: 0.7396 - val_loss: 0.5453\n",
                        "Epoch 129/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7345 - loss: 0.5404 - val_accuracy: 0.7400 - val_loss: 0.5459\n",
                        "Epoch 130/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7313 - loss: 0.5472 - val_accuracy: 0.7391 - val_loss: 0.5459\n",
                        "Epoch 131/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7348 - loss: 0.5439 - val_accuracy: 0.7400 - val_loss: 0.5446\n",
                        "Epoch 132/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7342 - loss: 0.5449 - val_accuracy: 0.7394 - val_loss: 0.5479\n",
                        "Epoch 133/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7340 - loss: 0.5425 - val_accuracy: 0.7400 - val_loss: 0.5459\n",
                        "Epoch 134/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7396 - loss: 0.5395 - val_accuracy: 0.7396 - val_loss: 0.5454\n",
                        "Epoch 135/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7292 - loss: 0.5467 - val_accuracy: 0.7398 - val_loss: 0.5464\n",
                        "Epoch 136/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7268 - loss: 0.5485 - val_accuracy: 0.7403 - val_loss: 0.5483\n",
                        "Epoch 137/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7393 - loss: 0.5387 - val_accuracy: 0.7394 - val_loss: 0.5449\n",
                        "Epoch 138/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7444 - loss: 0.5383 - val_accuracy: 0.7403 - val_loss: 0.5466\n",
                        "Epoch 139/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7372 - loss: 0.5415 - val_accuracy: 0.7402 - val_loss: 0.5460\n",
                        "Epoch 140/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7299 - loss: 0.5478 - val_accuracy: 0.7389 - val_loss: 0.5462\n",
                        "Epoch 141/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7390 - loss: 0.5383 - val_accuracy: 0.7396 - val_loss: 0.5487\n",
                        "Epoch 142/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7296 - loss: 0.5459 - val_accuracy: 0.7389 - val_loss: 0.5460\n",
                        "Epoch 143/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7351 - loss: 0.5430 - val_accuracy: 0.7409 - val_loss: 0.5462\n",
                        "Epoch 144/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7339 - loss: 0.5411 - val_accuracy: 0.7396 - val_loss: 0.5484\n",
                        "Epoch 145/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7324 - loss: 0.5444 - val_accuracy: 0.7400 - val_loss: 0.5465\n",
                        "Epoch 146/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7380 - loss: 0.5414 - val_accuracy: 0.7400 - val_loss: 0.5456\n",
                        "Epoch 147/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.7343 - loss: 0.5425 - val_accuracy: 0.7400 - val_loss: 0.5460\n",
                        "Epoch 148/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7392 - loss: 0.5370 - val_accuracy: 0.7392 - val_loss: 0.5464\n",
                        "Epoch 149/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.7319 - loss: 0.5434 - val_accuracy: 0.7396 - val_loss: 0.5452\n",
                        "Epoch 150/150\n",
                        "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7318 - loss: 0.5449 - val_accuracy: 0.7391 - val_loss: 0.5453\n",
                        "215/215 - 0s - 358us/step - accuracy: 0.7265 - loss: 0.5628\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized Loss 3: 0.5627670884132385, Optimized Accuracy 3: 0.7265306115150452\n"
                    ]
                }
            ],
            "source": [
                "# Model Optimization - Attempt 3: Add Dropout Layers\n",
                "nn_opt_3 = tf.keras.models.Sequential()\n",
                "\n",
                "# Add more neurons, additional hidden layers, and dropout\n",
                "nn_opt_3.add(tf.keras.layers.Dense(units=100, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
                "nn_opt_3.add(tf.keras.layers.Dropout(0.2))  # Drop 20% of the neurons randomly\n",
                "nn_opt_3.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
                "nn_opt_3.add(tf.keras.layers.Dropout(0.2))\n",
                "nn_opt_3.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
                "nn_opt_3.add(tf.keras.layers.Dropout(0.2))\n",
                "nn_opt_3.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
                "\n",
                "# Compile the optimized model\n",
                "nn_opt_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "# Train the optimized model\n",
                "history_opt_3 = nn_opt_3.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2)\n",
                "\n",
                "# Evaluate the optimized model\n",
                "model_loss_opt_3, model_accuracy_opt_3 = nn_opt_3.evaluate(X_test_scaled, y_test, verbose=2)\n",
                "print(f\"Optimized Loss 3: {model_loss_opt_3}, Optimized Accuracy 3: {model_accuracy_opt_3}\")\n",
                "\n",
                "# Save the optimized model\n",
                "nn_opt_3.save('AlphabetSoupCharity_Optimization_3.h5')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
